<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Ordered Beta Regressions · SubjectiveScalesModels.jl</title><meta name="title" content="Ordered Beta Regressions · SubjectiveScalesModels.jl"/><meta property="og:title" content="Ordered Beta Regressions · SubjectiveScalesModels.jl"/><meta property="twitter:title" content="Ordered Beta Regressions · SubjectiveScalesModels.jl"/><meta name="description" content="Documentation for SubjectiveScalesModels.jl."/><meta property="og:description" content="Documentation for SubjectiveScalesModels.jl."/><meta property="twitter:description" content="Documentation for SubjectiveScalesModels.jl."/><meta property="og:url" content="https://DominiqueMakowski.github.io/SubjectiveScalesModels.jl/OrderedBeta/"/><meta property="twitter:url" content="https://DominiqueMakowski.github.io/SubjectiveScalesModels.jl/OrderedBeta/"/><link rel="canonical" href="https://DominiqueMakowski.github.io/SubjectiveScalesModels.jl/OrderedBeta/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">SubjectiveScalesModels.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../BetaPhi2/">BetaPhi2() for Beta Regressions</a></li><li class="is-active"><a class="tocitem" href>Ordered Beta Regressions</a><ul class="internal"><li><a class="tocitem" href="#Function"><span>Function</span></a></li><li><a class="tocitem" href="#Usage"><span>Usage</span></a></li><li><a class="tocitem" href="#Validation-against-R-Implementation"><span>Validation against R Implementation</span></a></li></ul></li><li><a class="tocitem" href="../Choco/">Choice-Confidence (Choco) Model</a></li><li><a class="tocitem" href="../api/">Other Functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Ordered Beta Regressions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Ordered Beta Regressions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/DominiqueMakowski/SubjectiveScalesModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/DominiqueMakowski/SubjectiveScalesModels.jl/blob/main/docs/src/OrderedBeta.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Ordered-Beta-Regressions"><a class="docs-heading-anchor" href="#Ordered-Beta-Regressions">Ordered Beta Regressions</a><a id="Ordered-Beta-Regressions-1"></a><a class="docs-heading-anchor-permalink" href="#Ordered-Beta-Regressions" title="Permalink"></a></h1><p>Data from subjective scales often exhibit clustered responses at the extremes (e.g., zeros and ones).  This makes it challenging to model with regular Beta regressions. The Ordered Beta distribution allows for the presence of zeros and ones in an convenient way.</p><p><img src="https://github.com/DominiqueMakowski/SubjectiveScalesModels.jl/blob/main/docs/img/illustration_slider.gif?raw=true" alt/></p><h2 id="Function"><a class="docs-heading-anchor" href="#Function">Function</a><a id="Function-1"></a><a class="docs-heading-anchor-permalink" href="#Function" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="SubjectiveScalesModels.OrderedBeta" href="#SubjectiveScalesModels.OrderedBeta"><code>SubjectiveScalesModels.OrderedBeta</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OrderedBeta(μ, ϕ, k0, k1)</code></pre><p>This distribution was introduced by <a href="https://doi.org/10.1017/pan.2022.20">Kubinec (2023)</a> as an appropriate and parsimonious way of describing data commonly observed in psychological science (such as from slider scales).  It is defined with a Beta distribution on the interval ]0, 1[ with additional point masses at 0 and 1. The Beta distribution is specified using the <a href="../BetaPhi2/#SubjectiveScalesModels.BetaPhi2"><code>BetaPhi2</code></a> parametrization.</p><p><strong>Arguments</strong></p><ul><li><code>μ</code>: location parameter on the scale 0-1</li><li><code>ϕ</code>: precision parameter (must be positive). Note that this parameter is based on the <a href="../BetaPhi2/#SubjectiveScalesModels.BetaPhi2"><code>BetaPhi2</code></a> reparametrization of the Beta distribution,   which corresponds to half the precision of the traditional Beta distribution as implemented in for example the <code>ordbetareg</code> package.</li><li><code>k0</code>: first cutpoint beyond which the probability of zeros increases. Likely lower than 0.5 (also referred to as <code>cutzero</code> in the ordbetareg and <em>k1</em> in the paper).</li><li><code>k1</code>: second cutpoint beyond which the probability of ones increases. Likely higher than 0.5. Must be greater than <code>k0</code> (also referred to as <code>cutone</code> in the ordbetareg and <em>k2</em> in the paper).</li></ul><p>Note that when <code>k0=0</code> and <code>k1=1</code>, the distribution is equivalent to a Beta distribution (i.e., there are no zeros or ones).</p><p><strong>Details</strong></p><p><img src="https://github.com/DominiqueMakowski/SubjectiveScalesModels.jl/blob/main/docs/img/animation_OrderedBeta.gif?raw=true" alt/></p><p>The figure above shows the parameter space for <em>k0</em> and <em>k1</em>, showing the regions that produce a large proportion of zeros and ones (in red). Understanding this is important to set appropriate priors on these parameters.</p><p>Compared to the <code>ordbetareg</code> R package, the main difference is that:</p><ul><li><em>phi</em> ϕ (Julia version) = <em>phi</em> ϕ (R version) / 2</li><li><em>k0</em> and <em>k1</em> are specified on the raw scale [0, 1], and independently (in the R package, they are specified on the logit scale and k1 is expressed as a difference from k0).</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; OrderedBeta(0.5, 1, 0.1, 0.9)
OrderedBeta{Float64}(μ=0.5, ϕ=1.0, k0=0.1, k1=0.9)</code></pre><p><strong>References</strong></p><ul><li>Kubinec, R. (2023). Ordered beta regression: a parsimonious, well-fitting model for continuous data with lower and upper bounds. Political analysis, 31(4), 519-536.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/DominiqueMakowski/SubjectiveScalesModels.jl/blob/058df642066fbe4d3aab04b725a82ab0307961f9/src/OrderedBeta.jl#L8-L44">source</a></section></article><h2 id="Usage"><a class="docs-heading-anchor" href="#Usage">Usage</a><a id="Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Usage" title="Permalink"></a></h2><h3 id="Simulate-Data"><a class="docs-heading-anchor" href="#Simulate-Data">Simulate Data</a><a id="Simulate-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Simulate-Data" title="Permalink"></a></h3><p>Data with clustered extreme responses are common in psychology and cognitive neuroscience.  Ordered Beta models are a convenient and parsimonious way of modelling such data.</p><p><img src="https://github.com/DominiqueMakowski/SubjectiveScalesModels.jl/blob/main/docs/img/illustration_orderedbeta.png?raw=true" alt/></p><p>The model is based on a distribution with 4 parameters, 2 of which are the parameters of the <a href="../BetaPhi2/#SubjectiveScalesModels.BetaPhi2"><code>BetaPhi2</code></a> distribution (modeling data in between the extremes), and <em>k0</em> and <em>k1</em> delimiting fuzzy boundaries beyond which the probability of extreme values increases.</p><p>Let us start by generating data from a distribution with <em>known</em> parameters, and then fitting a model to recover these parameters.</p><pre><code class="language-julia hljs">using CairoMakie
using Turing
using DataFrames
using StatsFuns: logistic
using SubjectiveScalesModels

μ = 0.6
ϕ = 2.5
k0 = 0.05
k1 = 0.9

data = rand(OrderedBeta(μ, ϕ, k0, k1), 1000)
hist(data, color=:forestgreen, normalization=:pdf, bins=beta_bins(20))</code></pre><img src="c2dd87aa.png" alt="Example block output"/><h3 id="Prior-Specification"><a class="docs-heading-anchor" href="#Prior-Specification">Prior Specification</a><a id="Prior-Specification-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-Specification" title="Permalink"></a></h3><div class="admonition is-success"><header class="admonition-header">Summary</header><div class="admonition-body"><p>We recommend the following priors:</p><pre><code class="nohighlight hljs">μ ~ Normal(0, 1)  # Logit scale
ϕ ~ Normal(0, 1)  # Log scale
k0 ~ -Gamma(3, 3)  # Logit scale
k1 ~ Gamma(3, 3)  # Logit scale</code></pre></div></div><p>Because these 4 parameters come with their own constraints (i.e., <em>phi</em> <span>$\phi$</span> must be positive, <em>mu</em> <span>$\mu$</span>, <em>k0</em> and <em>k1</em> must be between 0 and 1), it is convenient to express them on a transformed scale (in which they become unconstrained and can adopt any values).</p><p>In particular, <em>mu</em> <span>$\mu$</span> is typically expressed on the <strong>logit</strong> scale, and <em>phi</em> <span>$\phi$</span> is expressed on the log scale (see <a href="https://dominiquemakowski.github.io/SubjectiveScalesModels.jl/dev/BetaPhi2/#Prior-Specification"><strong>here</strong></a> for details).</p><p>Priors for the cut points require a bit more thought. They share the same constraints as <em>mu</em> <span>$\mu$</span> (must be on the 0-1 scale), which lends itself to being expressed on the logit scale and then transformed back using the logistic function. However, additionally, we would like to ensure that <em>k0</em> &lt; <em>k1</em> (i.e., the lower boundary is lower than the upper boundary).  This can be achieved by setting a prior for <em>k0</em> that will have an upper bound at 0 (on the logit scale, corresponding to 0.5 on the raw scale) and a prior for <em>k1</em> that will have 0 as its lower bound.  In other words, we force the <em>k0</em> to be between 0 and 0.5 and <em>k1</em> to be between 0.5 and 1, which also solves the issue of k1 being smaller than k0.</p><p>This can be achieved using the <span>$Gamma$</span> and &quot;minus&quot; Gamma distributions (its mirrored version). We can then pick a shape of the Gamma distribution that maximizes the probability on values lower than 0.05 for <em>k0</em> and higher than 0.95 for <em>k1</em> (which is within the typical range in psychological science), such as <span>$Gamma(3, 3)$</span> and <span>$-Gamma(3, 3)$</span> (which mode is &quot;6&quot;, i.e., ~0.998 on the raw scale).</p><details><summary>See code</summary><pre><code class="language-julia hljs">using StatsFuns: logit

k0 = -Gamma(3, 3)
k1 = Gamma(3, 3)

fig =  Figure(size = (850, 600))

ax1 = Axis(fig[1, 1],
    xlabel=&quot;Prior on the logit scale&quot;,
    ylabel=&quot;Prior on k0&quot;,
    yticksvisible=false,
    xticksvisible=false,
    yticklabelsvisible=false)

xaxis1 = range(-30, 30, 1000)
vlines!(ax1, [0], color=:red, linestyle=:dash, linewidth=1)
vlines!(ax1, logit.([0.05]), color=:black, linestyle=:dot, linewidth=1)
lines!(ax1, xaxis1, pdf.(k0, xaxis1), color=:purple, linewidth=2, label=&quot;k0 ~ -Gamma(3, 3)&quot;)
axislegend(ax1; position=:rt)

ax2 = Axis(fig[1, 2],
    xlabel=&quot;Prior after logistic transformation&quot;,
    yticksvisible=false,
    xticksvisible=false,
    yticklabelsvisible=false)
vlines!(ax2, [0.05], color=:black, linestyle=:dot, linewidth=1)
lines!(ax2, logistic.(xaxis1), pdf.(k0, xaxis1), color=:purple, linewidth=2, label=&quot;k0&quot;)

ax3 = Axis(fig[2, 1],
    xlabel=&quot;Prior on the logit scale&quot;,
    ylabel=&quot;Prior on k1&quot;,
    yticksvisible=false,
    xticksvisible=false,
    yticklabelsvisible=false)
vlines!(ax3, [0], color=:red, linestyle=:dash, linewidth=1)
vlines!(ax3, logit.([0.95]), color=:black, linestyle=:dot, linewidth=1)
lines!(ax3, xaxis1, pdf.(k1, xaxis1), color=:green, linewidth=2, label=&quot;k1 ~ Gamma(3, 3)&quot;)
axislegend(ax3; position=:rt)

ax4 = Axis(fig[2, 2],
    xlabel=&quot;Prior after logistic transformation&quot;,
    yticksvisible=false,
    xticksvisible=false,
    yticklabelsvisible=false)
vlines!(ax4, [0.95], color=:black, linestyle=:dot, linewidth=1)
lines!(ax4, logistic.(xaxis1), pdf.(k1, xaxis1), color=:green, linewidth=2, label=&quot;k1&quot;)

fig[0, :] = Label(fig, &quot;Priors for Cut Points in Ordered Beta Regressions&quot;, fontsize=20, color=:black, font=:bold)
fig;</code></pre><img src="f1d2e84c.png" alt="Example block output"/></details><img src="f1d2e84c-001.png" alt="Example block output"/><h3 id="Bayesian-Model-with-Turing"><a class="docs-heading-anchor" href="#Bayesian-Model-with-Turing">Bayesian Model with Turing</a><a id="Bayesian-Model-with-Turing-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Model-with-Turing" title="Permalink"></a></h3><p>The parameters (and their priors) are expressed on the transformed scale, and then transformed using <code>logistic()</code> or <code>exp()</code> functions before being used in the model.</p><pre><code class="language-julia hljs">@model function model_ordbeta(y)
    # Priors
    μ ~ Normal(0, 1)
    ϕ ~ Normal(0, 1)
    k0 ~ -Gamma(3, 3)
    k1 ~ Gamma(3, 3)

    # Inference
    for i in 1:length(y)
        y[i] ~ OrderedBeta(logistic(μ), exp(ϕ), logistic(k0), logistic(k1))
    end
end

posteriors = sample(model_ordbeta(data), NUTS(), 1000);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chains MCMC chain (1000×16×1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 7.21 seconds
Compute duration  = 7.21 seconds
parameters        = μ, ϕ, k0, k1
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
 <span class="sgr1"> parameters </span> <span class="sgr1">    mean </span> <span class="sgr1">     std </span> <span class="sgr1">    mcse </span> <span class="sgr1">  ess_bulk </span> <span class="sgr1"> ess_tail </span> <span class="sgr1">    rhat </span> <span class="sgr1"> </span> ⋯
 <span class="sgr90">     Symbol </span> <span class="sgr90"> Float64 </span> <span class="sgr90"> Float64 </span> <span class="sgr90"> Float64 </span> <span class="sgr90">   Float64 </span> <span class="sgr90">  Float64 </span> <span class="sgr90"> Float64 </span> <span class="sgr90"> </span> ⋯

           μ    0.3725    0.0280    0.0008   1140.8421   915.7711    1.0003    ⋯
           ϕ    0.9317    0.0441    0.0012   1471.7402   673.3793    1.0030    ⋯
          k0   -3.2484    0.2021    0.0052   1552.5210   684.9964    0.9991    ⋯
          k1    2.0366    0.0927    0.0031    869.8915   822.6683    0.9996    ⋯
<span class="sgr36">                                                                1 column omitted</span>

Quantiles
 <span class="sgr1"> parameters </span> <span class="sgr1">    2.5% </span> <span class="sgr1">   25.0% </span> <span class="sgr1">   50.0% </span> <span class="sgr1">   75.0% </span> <span class="sgr1">   97.5% </span>
 <span class="sgr90">     Symbol </span> <span class="sgr90"> Float64 </span> <span class="sgr90"> Float64 </span> <span class="sgr90"> Float64 </span> <span class="sgr90"> Float64 </span> <span class="sgr90"> Float64 </span>

           μ    0.3180    0.3530    0.3717    0.3930    0.4247
           ϕ    0.8461    0.9025    0.9331    0.9599    1.0184
          k0   -3.6528   -3.3839   -3.2441   -3.1108   -2.8546
          k1    1.8681    1.9729    2.0362    2.0987    2.2229
</code></pre><pre><code class="language-julia hljs">means = DataFrame(mean(posteriors))

table = DataFrame(
    Parameter = means.parameters,
    PosteriorMean = means.mean,
    Estimate = [logistic(means.mean[1]), exp(means.mean[2]), logistic(means.mean[3]), logistic(means.mean[4])],
    TrueValue = [0.6, 2.5, 0.05, 0.9]
)</code></pre><div><div style = "float: left;"><span>4×4 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">Parameter</th><th style = "text-align: left;">PosteriorMean</th><th style = "text-align: left;">Estimate</th><th style = "text-align: left;">TrueValue</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "Symbol" style = "text-align: left;">Symbol</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">μ</td><td style = "text-align: right;">0.372499</td><td style = "text-align: right;">0.592063</td><td style = "text-align: right;">0.6</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">ϕ</td><td style = "text-align: right;">0.931724</td><td style = "text-align: right;">2.53888</td><td style = "text-align: right;">2.5</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">3</td><td style = "text-align: left;">k0</td><td style = "text-align: right;">-3.24841</td><td style = "text-align: right;">0.0373841</td><td style = "text-align: right;">0.05</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">4</td><td style = "text-align: left;">k1</td><td style = "text-align: right;">2.03659</td><td style = "text-align: right;">0.884585</td><td style = "text-align: right;">0.9</td></tr></tbody></table></div><h2 id="Validation-against-R-Implementation"><a class="docs-heading-anchor" href="#Validation-against-R-Implementation">Validation against R Implementation</a><a id="Validation-against-R-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Validation-against-R-Implementation" title="Permalink"></a></h2><h3 id="R-Output"><a class="docs-heading-anchor" href="#R-Output">R Output</a><a id="R-Output-1"></a><a class="docs-heading-anchor-permalink" href="#R-Output" title="Permalink"></a></h3><p>Let&#39;s start by making some toy data (the data itself doesn&#39;t matter, as we are only interested in getting the same results) and fit an Ordered Beta model using the <code>ordbetareg</code> package.</p><pre><code class="language-r hljs">library(ordbetareg)

data &lt;- iris 
data$y  &lt;- data$Petal.Width - min(data$Petal.Width)
data$y &lt;- data$y / max(data$y)
data$x &lt;- data$Petal.Length / max(data$Petal.Length)
# Inflate zeros and ones
data &lt;- rbind(data, data[(data$y==0) | (data$y == 1), ])
data &lt;- rbind(data, data[(data$y==0) | (data$y == 1), ])

ordbetareg(formula=y ~ x, data=data)</code></pre><pre><code class="nohighlight hljs"> Family: ord_beta_reg 
  Links: mu = identity; phi = identity; cutzero = identity; cutone = identity 
Formula: y ~ x 
   Data: data (Number of observations: 174) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Regression Coefficients:
          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept    -3.82      0.14    -4.09    -3.55 1.00     2701     2494
x             6.42      0.21     6.00     6.83 1.00     2999     2808

Further Distributional Parameters:
        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
phi        22.33      2.56    17.61    27.69 1.00     4220     3026
cutzero    -3.41      0.27    -3.95    -2.88 1.00     3202     3248
cutone      1.87      0.06     1.75     2.00 1.00     3323     3298

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre><h3 id="Julia-Implementation"><a class="docs-heading-anchor" href="#Julia-Implementation">Julia Implementation</a><a id="Julia-Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-Implementation" title="Permalink"></a></h3><p>Let us now do the same thing in Julia and Turing.</p><pre><code class="language-julia hljs">using RDatasets
using CairoMakie
using Turing
using StatsFuns: logistic
using SubjectiveScalesModels


data = dataset(&quot;datasets&quot;, &quot;iris&quot;)
data.y = data.PetalWidth .- minimum(data.PetalWidth)
data.y = data.y ./ maximum(data.y)
data.x = data.PetalLength ./ maximum(data.PetalLength)

# Inflate zeros and ones
data = vcat(data, data[(data.y .== 0) .| (data.y .== 1), :])
data = vcat(data, data[(data.y .== 0) .| (data.y .== 1), :])

println(&quot;N-zero: &quot;, sum(data.y .== 0) ,  &quot;, N-one: &quot;, sum(data.y .== 1))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">N-zero: 20, N-one: 12</code></pre><pre><code class="language-julia hljs">@model function model_ordbeta(y, x)
    μ_intercept ~ Normal(0, 3)
    μ_x ~ Normal(0, 3)

    ϕ ~ Normal(0, 3)
    cutzero ~ Normal(-3, 3)
    cutone ~ Normal(3, 3)

    for i in 1:length(y)
        μ = μ_intercept + μ_x * x[i]
        y[i] ~ OrderedBeta(logistic(μ), exp(ϕ), logistic(cutzero), logistic(cutone))
    end
end


fit = model_ordbeta(data.y, data.x)
posteriors = sample(fit, NUTS(), 1000)

# Mean posterior
mean(posteriors)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Mean
 <span class="sgr1">  parameters </span> <span class="sgr1">    mean </span>
 <span class="sgr90">      Symbol </span> <span class="sgr90"> Float64 </span>

  μ_intercept   -3.8212
          μ_x    6.4160
            ϕ    2.4163
      cutzero   -3.4649
       cutone    3.1838
</code></pre><div class="admonition is-danger"><header class="admonition-header">Important</header><div class="admonition-body"><p>Note that due to <em>Stan</em> limitations, the R implementation has <em>k1</em> (cutone) specified as the log of the difference from <em>k0</em> (cutzero).  We can convert the Julia results by doing: <code>log(cutone - cutzero)</code>.</p></div></div><p>The parameters for <em>mu</em> μ are very similar, and that of <em>phi</em> ϕ is different (but that is expected as a different parametrization is used).  The values for the cut points <em>k0</em> and <em>k1</em> (after the transformation specified above) are also very similar.</p><pre><code class="language-julia hljs"># Make predictions
pred = predict(model_ordbeta([missing for _ in 1:length(data.y)], data.x), posteriors)
pred = Array(pred)

fig = hist(data.y, color=:forestgreen, normalization=:pdf, bins=beta_bins(20))
for i in 1:size(pred, 1) # Iterate over each draw
    # density!(pred[i, :], color=(:black, 0), strokecolor=(:crimson, 0.05), strokewidth=1)
    hist!(pred[i, :], color=(:crimson, 0.01), normalization=:pdf, bins=beta_bins(20))
end
fig</code></pre><img src="574b387b.png" alt="Example block output"/><div class="admonition is-success"><header class="admonition-header">Plotting</header><div class="admonition-body"><p>The sharp number of zeros and ones makes it hard for typical plotting approaches to accurately reflect the distribution.  Density plots will tend to be very distorted at the edges (due to the Gaussian kernel used), and histograms will be dependent on the binning. One option is to specify the bin edges in a convenient way to capture the zeros and ones (which is what the <code>beta_bins</code> function does).</p></div></div><p><strong>Conclusion</strong>: it seems like the Julia version is working as expected as compared to the original R implementation.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../BetaPhi2/">« BetaPhi2() for Beta Regressions</a><a class="docs-footer-nextpage" href="../Choco/">Choice-Confidence (Choco) Model »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Friday 2 August 2024 12:22">Friday 2 August 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
